{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "mount_file_id": "1aaJJA1kG_lS31EVlngS_qdA4Z92CjDOd",
      "authorship_tag": "ABX9TyPuJA4Xcn/0scYVfRgLx0Ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasmbarboza/ICUFF_ML/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4aFRT0tTvcU",
        "outputId": "a733b4ee-fa1b-4d95-ce59-6ba9e46b7d29"
      },
      "source": [
        "!pip install numpy \n",
        "!pip install pandas\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM93Gl9aiVBn",
        "outputId": "ad4a0204-cc89-4937-fb21-f96c06e061d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTs25-UicT0"
      },
      "source": [
        "!cd /content/drive/MyDrive/IA/dataset/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXZVCCuivbW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-YD1Qvi2vX"
      },
      "source": [
        "filepath = '/content/drive/MyDrive/IA/dataset/DIAGNOSES_ICD.csv'\n",
        "dataset_dig9 = pd.read_csv(filepath, sep=',', decimal='.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8nSc_E4jtf-"
      },
      "source": [
        "def get_unique( data , columm ):\n",
        "  uniq_list = data[columm].unique().tolist()\n",
        "  return uniq_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLk8iHJZlDtP",
        "outputId": "a18ede28-a813-4759-a22b-ab9787935bd9"
      },
      "source": [
        "diagnoses = get_unique(data=dataset_dig9 , columm='icd9_code')\n",
        "patients  = get_unique(data=dataset_dig9 , columm='subject_id')\n",
        "admitions = get_unique(data=dataset_dig9 , columm='hadm_id')\n",
        "print(diagnoses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['99591', '99662', '5672', '40391', '42731', '4280', '4241', '4240', '2874', '03819', '7850', 'E8791', 'V090', '56211', '28529', '25000', 'V5867', 'E9342', '41401', '2749', '3051', '570', '07030', '07054', '30401', '2875', '2760', '0389', '41071', '78551', '486', '20280', '4582', '2724', '81201', '4928', '8028', '8024', '99812', '41511', '2851', 'E8859', 'E8788', 'V1259', '4019', '51881', '5770', '30390', '5781', '5845', '2848', '5722', '78559', '99592', '5711', '49390', '7299', '431', '4010', '5990', '2761', 'V103', '3569', '2859', '3970', '4266', '5859', '2948', '5691', '79092', '0380', '99673', '5761', '57451', '5856', '4538', '78552', '51882', '5119', '99659', '7211', 'V1588', '2380', '2930', '0414', 'V4502', 'V1046', '81249', '1985', '5070', '42830', '2765', '5849', '24220', '51919', '2767', 'E8889', '2720', '311', '43811', '53390', '43310', '6000', '412', '2762', '2554', '53081', '3310', '29410', '725', '2449', '99667', '71105', '2763', '99677', '7837', '45981', 'E8781', 'E8498', '73300', '04102', '40291', '7907', '2809', '9971', '4271', '4160', '4439', '49121', '00845', '42831', '1983', '6826', '1977', '1970', '5939', '28522', '0383', '44422', '2867', '56969', '4471', '41072', '1179', 'V446', 'V1042', 'V153', 'V1582', 'V4582', '78039', '5715', '452', '07070', '2800', '45620', '5724', '7895', '5723', '48282', '80125', '8602', 'E8348', '1510', '1978', '9992', '1962', '7140', '86404', '8504', '9584', '4275', 'E8232', '86389', '73689', '34591', '78001', '319', '56985', '39891', '3962', '496', '42789', 'V5861', '1972', '1625', '2639', '78791', 'E9331', '27739', '261', '58181', '27652', '5780', 'V0980', '2739', '45829', '7872', '2738', '04104', '53019', '04182', '3320', '29041', '4370', 'V441', '41400', 'V4581', 'V1079', 'V1201', '490', '04111', '29040', '44031', '56210', '9693', '29633', '9680', '9694', 'E9503', 'E9504', '7806', '5789', '27651', '2273', '2532', '70706', '80375', 'E8120', 'E8495', '87349', '1628', '1987', '1980', '1976', '19889', '20510', '5180', '70703', '28959', '2555', '0543', '42781', '78057', '42741', '3481', '78003', '2967', '4111', '29281', 'E9394', '20300', '1120', '2766', '585', 'V4281', '5290', '5750', '5754', '5185', '34982', '53240', '53140', '3453', '2866', '3485', '34831', 'V667', 'E9361', '51884', '42833', '25092', '03811', '70705', '4168', '32723', '27800', 'V5413', 'V1251', '56400', '82021', '42832', '99811', '9980', '4414', '40390', '99682', '5712', '07032', '5121', '56881', '5762', '80601', '82101', '80102', '99813', '34401', 'E8231', '3361', '8730', '8020', '1122', '37950', '56981', 'V1005', '1124', '41519', '1622', '7821', '57471', '3659', '42822', '58881', '78009', 'V4511', '71946', 'V0254', '85206', '85306', '2768', '7861', '30000', 'V1302', '71615', '3488', 'E9352', '78603', '1961', '9341', '28521', 'V1011', '70724', '48241', '20020', '2530', 'V8741', '56409', '6930', '2753', '7868', 'V1204', 'E9308', '27788', '48242', '28489', '4830', '45341', '2764', '45381', '35782', '28800', '37000', '78820', '4940', '3510', '27542', '6039', '60490', '71589', '52801', '28803', 'V600', '42823', '2811', '42821', '7213', '2721', '73730', '53084', '1629', '42732', '99731', '53089', '4011', '78724', '79029', '41001', '27801', '5601', '34590', '33385', 'E9479', '29570', '0388', '5854', '53551', '70714', '25002', '45340', '2841', '1965', '29562', '70712', 'V433', 'V4611', '03843', '03849', 'V551', '4239', '70707', '70720', '70722', '5728', '4739', 'V550', 'V5419', 'V5411', 'E9290', '25060', '3572', 'V1254', 'V440', '70721', '59970', '5989', '53642', '3441', '51909', 'E8798', '43853', '43810', 'V4984', '70723', '7810', 'V444', 'V442', '25062', '0417', '48283', '34400', '2752', '53649', '59960', '28860', '2689', '33829', 'V4986', 'V4572', '43819', '03812', '99664', '03840', '43882', '78720', '43889', '0416', 'E8796', '80501', '8052', '20410', '80502', '8911', 'E8809', 'E8490', '3669', '7580', '41041', '1623', '4588', '28984', '78959', '53789', '30393', 'V4983', '45621', '7994', 'V1581', '30391', '43401', '34290', '1570', '4531', '1890', '1966', '9982', 'E8700', '193', '5853', '78722', '5303', 'V4501', '60000', '47833', 'V462', '6191', '59582', '07044', '5641', '56949', '5533', 'V1041', 'V8801', 'E8792', '8830', '29181', '25080', '30301', 'V425', '25070', '44020', '99631', 'E8497', '49322', '79902', '340', '37410', '2989', 'V5865', '04112', '8600', '75321', '27650', '43850', '5602', '3963', '4589', 'V1083', '4254', '3968', '37230', '85225', '3315', '34570', 'V452', '72989', '79094', '78060', '2511', '8670', '59971', '4149', 'V1272', 'E9289', '43411', '3484', '4270', '72400', '34830', '42843', '1541', '5772', '5960', '0413', '71590', '78900', '7823', '85221', '1539', '42652', '9974', '51189', '47831', '5109', '36250', 'V4571', '43491', '514', 'E9379', '7802', '1508', '53082', 'V420', '71940', '53190', '2536', '7991', '4142', '4139', 'V1301', 'V1003', '4233', '71690', '4549', '28731', '5566', '5855', '2839', 'E9429', '03842', '1561', '1975', '45182']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZXb7_Uvnyn6",
        "outputId": "3f87b8c3-d8d6-4197-bf95-b26230ec7287"
      },
      "source": [
        "len(patients)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtqv0dlpmQGq"
      },
      "source": [
        "'''\n",
        "Pacienteid: { \n",
        "   admitions: []\n",
        "   diagnoses: [] \n",
        "}\n",
        "'''\n",
        "Mapdict = {}\n",
        "for patient in patients: \n",
        "  Mapdict[str(patient)] = {'admitions':dataset_dig9.loc[dataset_dig9['subject_id'] == patient]['hadm_id'].unique().tolist() , 'diagnoses':dataset_dig9.loc[dataset_dig9['subject_id'] == patient]['icd9_code'].unique().tolist()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TLtI7Freh8"
      },
      "source": [
        "diagnoses.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfGveqampDQC"
      },
      "source": [
        "''' \n",
        " \\  D0  D1 ... Dn \n",
        " P0 1   0  ... 0\n",
        " P1 0   0  ... 1\n",
        " ... \n",
        " Pn 1   1  ... 1\n",
        " '''\n",
        "Bigvet = []\n",
        "for patient in patients: \n",
        "  patVet = [] \n",
        "  for diagnostic in diagnoses:\n",
        "    if diagnostic in Mapdict[str(patient)]['diagnoses']: \n",
        "      patVet.append(1)\n",
        "    else: \n",
        "      patVet.append(0)\n",
        "  Bigvet.append(patVet) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "qRE8vIFTr15Y",
        "outputId": "6836cf5c-acd5-4d37-95bd-a49317abb392"
      },
      "source": [
        "Nw = pd.DataFrame(Bigvet)\n",
        "Nw.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>541</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "      <th>561</th>\n",
              "      <th>562</th>\n",
              "      <th>563</th>\n",
              "      <th>564</th>\n",
              "      <th>565</th>\n",
              "      <th>566</th>\n",
              "      <th>567</th>\n",
              "      <th>568</th>\n",
              "      <th>569</th>\n",
              "      <th>570</th>\n",
              "      <th>571</th>\n",
              "      <th>572</th>\n",
              "      <th>573</th>\n",
              "      <th>574</th>\n",
              "      <th>575</th>\n",
              "      <th>576</th>\n",
              "      <th>577</th>\n",
              "      <th>578</th>\n",
              "      <th>579</th>\n",
              "      <th>580</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>...</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.08000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.256432</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.368453</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.27266</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.171447</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.171447</td>\n",
              "      <td>0.196946</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.219043</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.256432</td>\n",
              "      <td>0.196946</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.287623</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.219043</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.171447</td>\n",
              "      <td>0.171447</td>\n",
              "      <td>0.140705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 581 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0           1           2    ...         578         579         580\n",
              "count  100.000000  100.000000  100.000000  ...  100.000000  100.000000  100.000000\n",
              "mean     0.070000    0.020000    0.020000  ...    0.030000    0.030000    0.020000\n",
              "std      0.256432    0.140705    0.140705  ...    0.171447    0.171447    0.140705\n",
              "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "50%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "75%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 581 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W10iHZP6xft3"
      },
      "source": [
        "def noise(size): \n",
        "  return np.zeros(shape=(size,581))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY1eTJMyyelO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8ZApIjmtyr54",
        "outputId": "35b01ab6-2060-44a8-b881-267d0836705a"
      },
      "source": [
        "''' \n",
        "x = [0 1 .. 1]\n",
        "Dis(x) = [p1 ... pn]\n",
        "Z = [1 1 .. 1] noise vector\n",
        "gen(Z) = [1 0 .. 1]  \n",
        "Dis(gen(z)) = [^p1 ^p2 ... ^pn]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\nx = [0 1 .. 1]\\nDis(x) = [p1 ... pn]\\nZ = [1 1 .. 1] noise vector\\ngen(Z) = [1 0 .. 1]  \\nDis(gen(z)) = [^p1 ^p2 ... ^pn]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT7NM5RAzn-E"
      },
      "source": [
        "def generator(hsize=[10, 10],reuse=False):\n",
        "    # Cria o modelo / Funciona como stack de opercoes\n",
        "    model =  tf.keras.Sequential()\n",
        "\n",
        "    # Cria primeira camada da rede neural usando os input Z / layer.dense cria uma rede neural do tipo densa \n",
        "    model.add(tf.keras.layers.Dense(hsize[1],name='GL1' ,activation=tf.keras.layers.LeakyReLU(),input_shape=(BATCH_SIZE,581)))\n",
        "\n",
        "    # Cria a segunda camada da rede usando o input h1(Z)\n",
        "    model.add( tf.keras.layers.Dense(hsize[1],name='GL2',activation=tf.keras.layers.LeakyReLU()))\n",
        "\n",
        "    # Cria a de saida camada da rede usando o input h2(h1(Z))\n",
        "    model.add(tf.keras.layers.Dense(581,name='GLout', activation='relu')) \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV9XXpaMz-YG"
      },
      "source": [
        "def discriminator(hsize=[10, 10],reuse=False):\n",
        "    # Cria o modelo / Funciona como stack de opercoes\n",
        "    model =  tf.keras.Sequential()\n",
        "    # Cria primeira camada da rede neural usando os input Z / layer.dense cria uma rede neural do tipo densa \n",
        "    model.add(tf.keras.layers.Dense(hsize[0],name='DL1'  ,activation='sigmoid',input_shape=(BATCH_SIZE,581)))\n",
        "    # Cria a segunda camada da rede usando o input h1(Z)\n",
        "    model.add( tf.keras.layers.Dense(hsize[1], name='DL2',activation=tf.keras.layers.LeakyReLU()))\n",
        "    model.add( tf.keras.layers.Dense(hsize[1],name='DL3', activation=tf.keras.layers.LeakyReLU()))\n",
        "    # Cria a de saida camada da rede usando o input h2(h1(Z))\n",
        "    model.add(tf.keras.layers.Dense(2, name='DL4'))\n",
        "    # Cria a de saida camada da rede usando o input h3(h2(h1(Z)))\n",
        "    model.add(tf.keras.layers.Dense(1,name='DLout', activation='relu'))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ProO1k0OZp"
      },
      "source": [
        "EPOCHS = 10000\n",
        "BATCH_SIZE = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpEqGiQR0dXz"
      },
      "source": [
        "gen = generator()\n",
        "dis = discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0T1xviY0rVo",
        "outputId": "40d54cc4-aee1-45de-88ff-5b8afc3c6378"
      },
      "source": [
        "Z = noise(10)\n",
        "print(Z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 581)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXyvz_mO081y",
        "outputId": "c196fb6c-0a32-45f9-8d45-16a9a87045cb"
      },
      "source": [
        "fake_data = gen(Z, training=False)\n",
        "print(fake_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(10, 581), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVf-OXuH1Opg"
      },
      "source": [
        "decision = dis(fake_data, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kusQC2Tw1mSv",
        "outputId": "ddc09c9e-bcbc-4174-f732-8bc54214c263"
      },
      "source": [
        "print(decision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]\n",
            " [0.13123296]], shape=(10, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0C_e9uI18J2"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lsDA9Od1_Km"
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNs1__ks2CyS"
      },
      "source": [
        "# Otimizador\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3,)\n",
        "#generator_optimizer =tf.keras.optimizers.RMSprop(1e-3)\n",
        "\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "#discriminator_optimizer = tf.keras.optimizers.RMSprop(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4poU5Px2GLl"
      },
      "source": [
        "epoch_vec=[]\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV0jTWuH3Q3N"
      },
      "source": [
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M6Vq6qJ3V80",
        "outputId": "a1e531dd-1f65-41b2-fdbc-d7448e42d191"
      },
      "source": [
        "len(Bigvet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mLX8kx72t32"
      },
      "source": [
        "def sample_data(matrix,batch):\n",
        "  sample =[]\n",
        "  for integer in range(batch): \n",
        "    sample.append(matrix[randint(0,len(matrix)-1)])\n",
        "  #print(sample)\n",
        "  return np.array(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCAAjSat2RHL"
      },
      "source": [
        "@tf.function\n",
        "def train_step(Y):\n",
        "    Z = noise(BATCH_SIZE) #\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      #print('Entrei no loop')\n",
        "      fake_data = gen(Z, training=True)  \n",
        "      real_output = dis(Y, training=True)\n",
        "      fake_output = dis(fake_data, training=True)\n",
        "      print(gen.)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      #print(gen_loss)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = tape.gradient(gen_loss, gen.trainable_variables)\n",
        "    gradients_of_discriminator = tape.gradient(disc_loss, dis.trainable_variables)\n",
        "    del tape\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3mgMS1O9ZO1",
        "outputId": "9d9b71ac-f2dc-4b0c-c2de-887b73b9c913"
      },
      "source": [
        "gen.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "GL1 (Dense)                  (None, 10, 10)            5820      \n",
            "_________________________________________________________________\n",
            "GL2 (Dense)                  (None, 10, 10)            110       \n",
            "_________________________________________________________________\n",
            "GLout (Dense)                (None, 10, 581)           6391      \n",
            "=================================================================\n",
            "Total params: 12,321\n",
            "Trainable params: 12,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63wTDize_1Xk",
        "outputId": "da62f3ef-a908-423d-8a23-c81eb63fe095"
      },
      "source": [
        "dis.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "DL1 (Dense)                  (None, 10, 10)            5820      \n",
            "_________________________________________________________________\n",
            "DL2 (Dense)                  (None, 10, 10)            110       \n",
            "_________________________________________________________________\n",
            "DL3 (Dense)                  (None, 10, 10)            110       \n",
            "_________________________________________________________________\n",
            "DL4 (Dense)                  (None, 10, 2)             22        \n",
            "_________________________________________________________________\n",
            "DLout (Dense)                (None, 10, 1)             3         \n",
            "=================================================================\n",
            "Total params: 6,065\n",
            "Trainable params: 6,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKpo_h1A2ULF"
      },
      "source": [
        "epoch_vec = []\n",
        "for x in range(EPOCHS):\n",
        "    Y = sample_data(Bigvet,batch= BATCH_SIZE)\n",
        "    train_step(Y)\n",
        "    if x in [2500,5000,7500,10000]: \n",
        "      epoch_vec.append(gen(Z,training=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82pewLcy4DQB",
        "outputId": "fd0cc789-045b-4226-8620-10475fa1eddb"
      },
      "source": [
        "z = noise(BATCH_SIZE)\n",
        "fake = gen(Z, training=False)\n",
        "print(fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(10, 581), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WFcTQKw5MD9",
        "outputId": "5dae3224-f7fd-4e5d-8ac4-66f6789df0ea"
      },
      "source": [
        "print(dis(fake, training=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]], shape=(10, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}